# Since the ".env" file is gitignored, you can use the ".env.example" file to
# build a new ".env" file when you clone the repo. Keep this file up-to-date
# when you add new variables to `.env`.

# This file will be committed to version control, so make sure not to have any
# secrets in it. If you are cloning this repo, create a copy of this file named
# ".env" and populate it with your secrets.

# When adding additional environment variables, the schema in "/src/env.js"
# should be updated accordingly.

# Prisma Database Configuration
# https://www.prisma.io/docs/reference/database-reference/connection-urls#env

# Local Development (Docker PostgreSQL with pgvector)
# Set this for local development - matches docker-compose.yml postgres service
DATABASE_URL="postgresql://neon:npg@localhost:5432/neondb"

# Optional: POSTGRES_PORT controls the local docker Postgres host port mapping (default: 5432)
# If port 5432 is occupied, set POSTGRES_PORT=5433 in .env and update DATABASE_URL accordingly
# POSTGRES_PORT=5432

# Optional: override the local connection string (advanced use only)
# LOCAL_DATABASE_URL="postgresql://devuser:devpassword@localhost:5435/devdb"

# Production Database (Neon Cloud)
# These are for the production DB, only needed when PRODUCTION=true
# DATABASE_URL="postgresql://username:password@host/dbname?sslmode=require"
# Uncomment next line if you use Prisma <5.10
# DATABASE_URL_UNPOOLED="postgresql://username:password@host/dbname?sslmode=require"

# Redis
# UPSTASH_REDIS_REST_URL="https://your-upstash-instance.upstash.io"
# Once again these are for the production redis server
# UPSTASH_REDIS_REST_TOKEN="your_upstash_token"
# Set these for local REST proxy parity
UPSTASH_REDIS_REST_URL="http://localhost:8079"
UPSTASH_REDIS_REST_TOKEN="dev-token"
UPSTASH_REDIS_REST_PORT="8079"

# Production toggles remote services (Neon + Upstash)

# Clerk
CLERK_SECRET_KEY="your_clerk_secret_key"
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY="your_clerk_publishable_key"

# OpenAI API Key (REQUIRED for embeddings - used for both generation and querying)
OPENAI_API_KEY="your_openai_api_key"

# AI Provider Configuration for RAG chat endpoint
# Supported providers: "anthropic" | "openai" | "google"
AI_PROVIDER="anthropic"

# AI Model to use (provider-specific model names)
# Anthropic examples: "claude-3-5-sonnet-20241022", "claude-3-opus-20240229"
# OpenAI examples: "gpt-4-turbo", "gpt-4o", "gpt-3.5-turbo"
# Google examples: "gemini-2.0-flash-exp", "gemini-1.5-pro", "gemini-1.5-flash"
AI_MODEL="claude-3-5-sonnet-20241022"

# API Keys for AI chat responses (only the one for your chosen AI_PROVIDER is required)
ANTHROPIC_API_KEY="your_anthropic_api_key"
# GOOGLE_API_KEY="your_google_api_key"

# Embeddings Storage Backend
# Choose between "json" (file-based) or "postgres" (pgvector database)
# Default: "json" for backward compatibility
# Set to "postgres" after running: bun run embeddings:generate <roadmap> --use-postgres
# Postgres backend requires DATABASE_URL to be configured with a pgvector-enabled database
EMBEDDINGS_BACKEND="json"
